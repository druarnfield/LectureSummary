Hi everyone, welcome to week two. In this lecture we're going to look at some ways of plotting multivariate data. This week you should be reading through chapter three before looking at these notes or listening to this recording or trying this tutorial. And if you haven't already done so in week one, you should go back to the R companion notes in the week one block on the study desk and particularly look at chapters three and four that work through some basic plotting code. The data sets I'll be using in this lecture are the sparrows2.txt, mandiblefull.txt and twdecade.dat. The first two are from Manly and the third one is a separate data set that I've put together. All of these are available in the week two block on the study desk. The R code will be plots in R, make profile plot and print mean and standard deviation by group. These are class two function scripts and I'll show you how to run a function script in R. We'll also be using quite a few packages in this lecture. We'll be using the car package, scatterplot3d, RGL, Rcolorbrewer, ggplot2 and reshape2 and I'll show you how to install packages in RStudio. The objectives of this week are to understand the difficulties associated with displaying multi-dimensional plots. We'll be looking at various types of plots and their application in R. So plotting data is one of the first basic steps of any data analysis. It is always best to plot your data first. It helps you understand the nature of your data, any problems that may be arising in your data and it will also help you understand whether your final analysis results make logical sense. The types of plots we use are fundamentally determined by the types of variables that we want to display. So if we have two continuous variables, for example, we could try a scatterplot. But if we had two categorical variables, that would be completely inappropriate. So of the wide range of plots available to us, the types of variables we have dictate to a large extent which of those plots would be appropriate for our data. Now sometimes this can narrow you down to just one plot that's appropriate, but sometimes there's still multiple options available and each plot may actually highlight different aspects of your data. So it can be a good idea just to try several plots and see what they do, try and interpret the plots and see if anything interesting is coming out of it, whether it's revealing anything interesting about your data that isn't obvious just by looking at columns of data. One of the biggest challenges dealing with multivariate data is that our human brains find it really difficult to visualise and fully comprehend details above three dimensions. We can look at a two-dimensional plot on a screen or a page and we can understand the axes and understand the relationship of the observations to each other within the plot space. If we extend that to a three-dimensional plot, we can still kind of understand how each of the points within the plot relate to each other and how the axes relate to each other. But above three dimensions, our brains start either missing detail or misinterpreting the information within the plot. So it's not just a technology issue, it's not just that it's hard to build plots and visuals that are above three dimensions, especially when we're generally restricted to either showing those plots on a two-dimensional page or screen. As well as this technical issue, there is just the fact that our human brains find it difficult to interpret information above three dimensions. And so even if we can do it, it's often really ill-advised because it leads to misinterpretation of our data. Last week I mentioned that in multivariate analysis there's two main types of analysis. One is dimension reduction and one was classification. So the dimension reduction side is related to this difficulty we have in plotting multidimensional data. So the dimension reduction analysis tried to take our number of original variables and reduce them down to a smaller number of variables to help us understand and interpret the data, to help us understand the relationship between the variables, the columns of data, and the observations, the rows of data. And this also can help us then plot that because the human brain likes looking at visuals rather than reading chunks of text. The advertising industry actually figured this out in the 60s. And advertising used to be paragraphs of information provided to consumers to try and convince them to buy a certain product. And in the 60s and 70s it was realised that a picture is worth a thousand words. And so advertising fundamentally changed from blocks of text to lots and lots of visuals. But this example should also be a bit of a warning to us because from our perspective we need to be really cautious that any results or visuals that we produce have the least amount of chance of being misinterpreted. Advertising, the way they use visuals, don't mind if things are misinterpreted. They understand that when a human brain sees a visual, what they see they interpret as the truth before they actually read any text. So if you have misleading axis labels, if you have a two-dimensional plot and you've made the bars in that plot three-dimensional so it offsets the aspect and makes an effect look bigger than it actually is when it's measured on the y-axis, for example, all of those things are to the advantage of the advertising industry. They take advantage of the way brains interpret visuals in an instance. So from our perspective though, we need to be very careful that the results we produce are not misinterpreted. So that means we need to be more rigorous in the way we display our plots. So the more complex a graph, the greater the potential for misinterpretation and the loss of fine detail. The more complex it is, the more likely that the reader or the viewer is going to just take away the broad, standout, obvious information and not look at the fine detail. So if you have something in your graph that you really think is important that the reader not skim over, you need to find ways to make that stand out. And that could be bold text, coloured text, things like that. But if you know that there is an obvious point at which your plot or your graph or your visual can be misinterpreted, it is your job to try and find a way to make sure it's not overlooked. Using index variables derived from multivariate analysis that combine the effects of several variables is one way to incorporate more information into a 2D plot. By index variable, I mean that in the dimension reduction process of some multivariate analysis methods, we create new variables from our original variables. These are compound variables. They're based on some combination of our original variables. And they're often referred to as index variables or combination variables or compound variables or factors or components. And as I say here, what they allow us to do is take our original 10 variables, for example, and combine them in such a way that we can display just two new variables and represent the vast majority of the variance incorporated in the raw data, but displayed in a way that's much more easily interpretable. In these dimension reduction methods, there is always some loss of information in reducing down to fewer variables. And that's what we'll discuss this semester when we're looking at those methods, how much information are we willing to use for improved interpretability. In addition to reducing the data down dimension-wise, we can also use our plotting methods that we're really familiar with, so our 2D plotting methods where we just plot one variable against another variable. When we have continuous variables, we would use scatter plots for that. And what we can do is lots of pairwise comparisons amongst our variables and produce a Draftsman plot. And we'll be looking at those in a moment. Draftsman plots can be helpful in screening because you're comparing each variable to each other. And so you can look at those two-dimensional relationships, and you might see observations that stand out in some variables or some variables that behave differently when compared to all other variables. And that can help you in your data screening and data cleaning process. But again, because they're only showing pairwise comparisons, we're not getting that overall multi-dimensional picture. So we're still not seeing how all the variables relate to all of the other variables. Using symbols and graphs can help us represent the totality of variation. So if you have two continuous variables and you're producing a scatter plot, but you also have a categorical variable, a factor variable, you could color code the observations within your plot to represent that factor. And we'll be having a look at an example of that in a moment. And profile plots can help us see differences between groups based on all the variables, and we'll also look at those. So in Chapter 3 of Manly, he covers a lot of these examples. And what we're going to do in this lecture is work through some examples in R using the same data sets as well as an additional data set to try and reproduce some of his graphs or something similar at least. Again, just a reminder of those R companion notes. There's quite a bit on basic plotting code in R in those notes that you might want to work through first. So within R, there's three different plotting systems. There's a base plotting, lattice plotting, and ggplotting system. Lattice plot and ggplot require that you install a package through the CRAN repository, and we'll have a look at how to do that in a second. Base plotting doesn't need you to install any packages. You can do it straight from the console. Some plots in base plotting require the use of functions developed within R scripts. So a function is a script that runs a lot of if-then loops, for loops, et cetera, to build up complex plotting systems so that you only have to tell the function which variables you want to run, and it will do the looping for you. And we'll have a look at how those work in a moment as well. So in the base plotting system, basically what you do is you build up a plot from a blank canvas. You define everything like the colors, the widths of any bars, et cetera, the margins in the plot, the spaces. You pretty much can define everything within the base plotting system, and you can add to a plot. So if I produce a scatter plot and have the output of that scatter plot, I can run some additional code that will add, say, a regression line to that plot. It's much more difficult to take things off the plot. You would have to start from the beginning again. But you can add things as you go to the plot. The lattice plotting system has quite a lot of defaults that you can't really change. And plots are created with basically one function name. So bwplot would create box or misker plots. Lattice is really good for plotting lots of plots together, like Jasmine's plots, et cetera, when you want to do lots of comparisons of variables in plotting and have them all in the same plotting window. Once you create a plot, though, you can't just keep adding to it. You have to start from the beginning and change the code. But again, it's a lot more restrictive, actually, than the base plotting system. ggplot is sort of midway between base and lattice plot. It has a lot of defaults in the formatting, so it makes a lot of choices for you. But then you can still go back in and customise the plot to what you want. ggplot is probably the most powerful of the three. In the code I'm using today, I'm going to use base plotting and ggplot. But I really encourage you this week, after you've worked through these examples in this lecture and the tutorial, that you really play around with all three plotting systems as much as possible. If you can come up with some code for your code library that you can start developing, that you can always go back to, get some code working, try lots of different plots. So I've just sort of covered this, that each plotting system allows some different functionality. There are often many ways to display variables in similar ways, and some plots require the use of functions. So I'm going to provide the code, as I said at the start of this lecture, the code will be available on the study desk in the week two block for this week. But I really encourage you to start building up your own code library. It's also really important to remember that the form you get your data in is not the only form that you can have that data in. So often you need to substantially reorganise data to be able to get the plot you want, or to do the analysis you want. So it's plotting, when you do just start plotting, doing some really basic two dimensional plots, that really helps you start understanding your data, what your rows mean, what your columns mean, what kind of observations, how much variation within each variable, those kinds of things. And then that can lead you to thinking of ways of reorganising your data to plot it in different ways to highlight different aspects of the data. Remember I won't ever be testing you formally on R, I'm never going to ask in assignments questions about R code, but you absolutely need to use R code in all of your assessable items. So in the notes here now, I've just got examples of the code and the output for several different plots. I'm going to skip over to R now and work through it there. So the first thing I'm going to do is just import the Sparrow text. And just to check that it's imported correctly, I can use head and tail SP, I've called the data frame SP here. I can use head and tail just to see the top few rows and the bottom rows of the data. So here's the top six, and I can see that all of my variables have entered correctly. And then I can do the tail, the bottom six, and I can see that I have the correct number of total number of observations. And I can also see that survival here is coded, so the birds either survived or they didn't, and we have a one and a two for survival and not survival. I'm just going to talk a little bit about attaching data sets. So R is an object-orientated language, which means it likes to name things so that it can recall them. So as we named this data frame SP here, if I attach SP, it means I can call any of the variable names that are in SP without having to first tell R to look in this data frame. If I had, I'll just have a look here, so here in this scatterplot code here, you'll see that I have just used the variable names extent and length here, and I can do that without first having to say SP$extent or SP$length, because I will have attached SP. If I had another data set, say, of parrots, where I'd measured exactly the same things and had the same variable names, and I had SP attached and parrots wasn't attached, you can only have one data frame attached at a time, and I wanted length of parrots and just typed length, it would be drawing it from the data frame that's attached. So I would first have to give it the data frame name first, so it would have to be, say, PAlength or PAextent to be able to tell R which data frame I want to draw it from. If you're running multiple data sets, I suggest not attaching, because you'll get confused about which one is attached. It's better just to get in the habit of always naming the data frame and the variable name. If you're just running one data frame, then often it just saves a bit of time by attaching it so that you don't have to keep writing out the data frame name as well. If you attach at the end, down here, somewhere you should also detach when you're finished that analysis. Otherwise, R will keep drawing the variables extent, length, head, humerus, sternum, and survival from SP and not any other bird file you may bring in. So I'm just going to attach now, and I'm just going to use the base plotting system, and I want to plot from my SP data frame. I want to plot columns 2 to 6, so I want to plot length, extent, head, humerus, and sternum. 2, 3, 4, yeah. Now you'll see in this line of code here, there's a comma first. So the comma says to plot all rows. If I wanted to define the rows, I could do that first. I could plot rows 10 to 20, and I'd write that similar to how I've written the variables 2 to 6 here, and then a comma, and then the variables. But I want to plot all rows. So basically, all rows means there's a blank before the comma. So I'm just going to run this, and I get this plot here. Now I'm just going to hit Zoom here to extend it out a little bit, so it's a bit easier to see on the screen. Now this plot is similar to plot 3.3 in Manly. It's a draftsman's plot, and it's basically a pairwise scatterplot between all of our variables. It's really important that you understand what the axes mean. So here we have length, and if we look down the bottom here, this is the axis for length. Here we have extent, and this is the axis for extent. And head, here is the axis for head. So when I'm working across here, the x-axis is whatever is in the label box here. Now for this plot here, I have length on the x-axis, and on the y-axis, you'll see that this axis, the labels here, the range of the values here is the same as across the top here for extent. So the y-axis here is extent. So to read these plots, you go down for the x-axis, so this is extent, and across for the y-axis, so this is head across on the y. And here's our actual values here. So it looks like there's a sort of at least a partial linear relationship between all the pairwise variables, and they're always positive. There's none that seem to have a negative relationship with each other. And there's no, well there may be a couple of little outliers in certain places, but there's quite a bit of scatter in this plot generally, so it's a bit hard to tell. This one here between head and sternum, there's quite a bit of scattering like that. And with these ones, because they're diagonal, it's often easy just to pick a diagonal, so I either look at the bottom diagonal or the top diagonal, because they represent the same relationships. Otherwise you're sort of trying to look at too many plots, and it gets a bit overwhelming. Okay, so I'm just going to close that one down. So to do just a basic Draftsman's plot in the basic form.plotting system, the code is very simple. If you're not using KnitR to produce your assignments and you want to export this, that's really easy to do. Just click the export button and you can save it as an image and then import that into your Word document. So the next dataset we're going to use is, we're going to need a package called Car. So to install a package in R, just go to the packages tab here and you'll see the list of packages installed on your computer. So the easiest thing to do is if Car is not installed, I do have it installed, but if it's not, just click on install, type the package name here, Car, make sure you're referred to the repository CRAN here, and most importantly here, make sure install dependencies is ticked. Most packages need some other packages to run correctly and they're called dependencies, so if this is not ticked, your package won't run properly and it'll keep asking you for other packages which you then have to go and search for, install, etc. So as long as this is ticked, the package once installed should work correctly. Then you should just be able to click install and as long as you've got a good internet connection and there's no problem with the CRAN repository at that moment that you're trying to install, everything should work fine. If you don't want it to go to the default location you can just change that here, if you want it to go somewhere else on your computer, or if you're using a university computer, you can save it to your USB drive if you want to. That way next time you need it, you can install it straight from the USB drive and not have to worry about going to CRAN. Some packages can take a couple of minutes, so just make sure you're prepared for that. So once a package is installed, we then need to load it into R and to do that we use this code library that tells R that we actually want to use this package right now. In this packages window in the bottom right of my screen here, we can just tick the box to start car working. I really strongly suggest you don't do that, always use code. If you don't put the code here and just have the scatterplot code below and you save this code and come back to it in two months, you won't remember that you had to install car. You won't remember that you went over here and ticked this box. For reproducible research, you put everything in code that you can. You don't have some things in code and some point and click. The point and click stuff is not reproducible, you won't remember you did it. Put everything in code that you can. In your code, make sure you put as many comments as you can. So here you'll see I've used the hash for commenting. So I'm going to just run the library line here and just wait a minute. It's just installing and you'll see it's installed fine now. And if we look over here, the box has been ticked so it's installed fine. So now I'm going to create a scatterplot and I want it to be extent against length and I want to do it by survival because remember survival is a categorical variable so I use the vertical line from my keyboard here to say I want to group my scatterplot based on whether the bird was a survival or not a survivor. You can then see here I have code here to put an X label and a Y label on my X and Y axes and I don't want a regression line and so then I don't want a smoother either to that line. So I'm just going to run this scatterplot and I'll just, I won't zoom that one. So you can see here that I have the total length on my X axis and I have extent on my Y axis. So remember when we're doing these plots it's Y against X so make sure you get those around the right way in the code. Y comes first and then X. And I've coded these by survival 1 and 2. I really should fix up that legend and make it say 1 is survived and 2 is not survived, make it much more easily interpretable. Just looking at our plot here it looks like the range along our X axis that the number 2 not survived that has a slightly bigger range than the little circles. Little circles are all within the range of the little triangle so 1's and 2's survived and not survived. And on our Y axis it looks like the range of each variable is pretty much the same. So I would say that there's pretty much complete overlap of the two groups here. There's no real distinction. If anything I would think that the survive are sort of within the range on both variables of the not survived. So this plot is similar to figure 3.1 in Manly. You can have a bit of a comparison there. Next I'm going to use scatterplot matrix code. And again this is telling it I want it to do all rows and columns 2 to 6 similar to the plot coding I used up here to define which variables I want to plot. So scatterplot matrix is a particular function within the base plotting and if I run that. Oops, sorry I just had that one piece highlighted. There we go. So this I will just zoom this one up a little bit so we can see a bit more clearly. This is again like the Draftsman plot and figure 3.3 in Manly except we get a little bit of a distribution plot here for each individual variable by themselves and we get some sort of lines and confidence intervals fitted which I wouldn't pay much attention to with such a small data set. These sort of lines are a bit misleading I think. But what it's showing us is none of the variables are horribly off normal really. I mean for a small data set they're doing quite well. And these scatterplots again the x and y axis labelling works the same as what we discussed in the previous Draftsman plot. So length is on the x axis here and for this plot here extent would be on the y axis. So here I'm calling library now scatterplot 3D. So again you would need to install the package scatterplot 3D by clicking on the packages tab and doing an install. I already have it installed so I can just call that library and that's worked fine. And I want to create a 3D library because remember I discussed earlier the problem with these pairwise comparisons. They're useful but they still don't give us that multi-dimensional impression of what's happening with the data. Given that we have six variables the 3D plot is really only going to help us with three variables at a time but it might be interesting to have a look at. So with scatterplot 3D function code we tell it the y, our x and our z variable now and we can give it a main title and we want to base colouring of the observations on survival. So the one or the two. And here I get a static like a fixed 3D plot. So I've got heurist, extent and length here and I can get a bit of a visual. You can't really rotate that so what you can do is you can use library RGL which is another package you would need to install and I can use plot 3D similar code here, extent, length and heurist. I tell it my three variables and I can give it a colour and size etc. There's a few more parameters you can change. But if we look at this one, this one will actually open plots in a separate window. You should see that it opens up this little extra window which you can play around with a bit. So then you can just hold your left mouse button down and do a bit of zooming and stuff. So this kind of thing, this sort of interactive display is good for you because you get to see your data from different aspects. It's not good for papers which you have to put a static visual in. It could be good, better than say the original 3D plot if you find an angle that highlights a particular point that you really want to highlight that this static angle doesn't give you. You could rotate this around until you find a particular aspect that is what you want to display and then put that static image in your work. OK, so we could play with that all day but I'm going to close that down. So that's using library RGL and then the function is plot 3D. So remember that you can, you Google any of this, you will find that each of these functions have specific options available, many more options probably than what I'm showing here. I'm showing pretty basic ones so you should explore those. So we have already plotted multiple plots for a window by using the Draftsmen plot and this plot, this original plot and base plot. But if you are plotting, you are creating code to plot individual plots that you then want to display in the same window, that's also possible. So what we use is this row similar to this, a row of code similar to this. We use par, which just means parameters and we use MF row which is multi-figure row. So we say the multiple figures by row, we want two rows and one column of plots. That sets up the window and then we give it the plot information. So if I run this par MF row, you'll see nothing actually happens, it's just starting off the plotting information for R and telling it how ultimately it wants it to be displayed. I want to do a plot of extent with length and a plot of head with length. So I'll plot the first one and you'll see here that originally I said I want two rows and one column. So I want to have one plot and then another plot below. So it's put the first plot in, it looks horrible because of the size of the window but you can get the gist of what I'm saying and then if I run the second plot code it will put it below it. If I zoom this it might look a bit better, there you go. So I have two rows and one column of plots. OK. Now you can set that up however you want. The first one is the number of rows and the second value is the number of columns. I could have done it as one two which means I'd have one row and two columns of figures. So if I run that and then rerun my two plot you'll see I now have one row and two columns of figures. So you can rearrange the way you want to display your data. Now it's important that you set it back to the default because if I just want one figure per window now this latest par code is fixed so I need to revert it back by just setting it as one one again. So I'll just run that code. OK so next we're going to look at some profile plots and we're going to use one of the function files. We're going to use the profile plot function. So first we need another package, rcolabrewer. So you need to install that and then use the library code to call it. So if I click over here this is the function we're going to use. So this has been developed by someone else and we're just going to use it. Now a function starts out, there's some notes on functions in the rCompanion, but a function starts out by saying what is the user going to have to give to the function to make the function work. The user is going to have to give them something that is called myList and something that is called names and then this is the actual function so this is what r does with that myList and the names. We'll have a look at what those are in a second but for example here it first needs something, it wants to create something called numVariables and basically that's going to be the length of myList and then it's going to figure out the colours for the plot and then it's going to run through iteratively for loops and ifs etc, if and else statements and run the code. When you have a function like this that's part of code and not just automatically called from a function name in a package, what you do is you just select everything in the function and run it. Now r has stored this that it needs myList and it needs names. So then if we go back to our code here, I'm going to create two objects, one called names and one called myList. In names I'm going to have the names of the variables that I want to run the plot on so I'm going to create that and in myList it is just the headings of those variables. So here in names it's the actual variables and here in myList it's just the labels for those variables. So I'm going to create myList. Now I'm just going to flip back to the function file again. So what I have to do to make this function work is to use whatever the function is called and give it the names I've put in here. So if I hadn't called it myList for names, if I'd called it two other things, I'd just need to put them there in that order. So here I have used those names so that's no problem. So here's the name of the function and I want it to call myList and names. And there we go, it's produced the plot we wanted. So the first part is to run the function first and then once you've created, you check on this function what are the objects it needs to run and you create those objects for your data. And then you run the function so this is actually running the function with your data and you get the plot you need. So this plot, there's not an example of it in Manly but basically what it is, it's a profile plot for the variables. So we've got extent, length, head, et cetera here and these are all of the individuals, this index value here. Index is used in a different way here. These are just the individuals in our data set. Now because these different variables are measured on different scales, so extent and length are much bigger, it's in the 250s and the 150s, than these other variables which are measuring just body parts, so head, et cetera. So they're obviously much smaller than the overall extent or length. This can be a little bit difficult. It may be more interesting just to run this function on these smaller variables, smaller in the sense that they're measured on a smaller scale, and to see where there's much fluctuation. For these extent and length, there is some variation, quite a bit actually, between some individuals here. It's not perfectly straight lines. But again, it's not a great plot for this data but it may be for other data. So it's worth hanging on to that code. Okay, so that's all we're going to use the SPARROW data set for. So I'm just going to detach that. And the next data set we're going to look at is the mandible full data set. This mandible full data is actually from table 4.5 in Manly. It's not the one in chapter one. It's another data set that's in table 4.5 of Manly. Okay, so I'm just going to import that data and attach it. Have a look at the head just to see that everything's entered correctly. And I have the group which is the type of the species. And then I have the nine variables that are listed in table 4.5 and the sex of the dog or canine. I'm also going to run structure which is a function I really like running because I find it really helpful. So it tells me I have 77 observations and 12 variables which is great. But it tells me how each is important. So I can see here that group is just an integer. So it's just each of the species is given a number. If I want to use that as a factor at any time I'm going to have to remember that I'm not going to need to tell R that it's actually a factor, a categorical grouping rather than just an integer. And same for sex here. It's just regarded as an integer. But we'll be looking at those kind of manipulations a bit later as well. So I have all of this data. What I actually want is the means and the standard deviations by group. So I'm going to use another function R code script file to do that which is available on the study desk in the week 2 book. And that's called print means and SD by group. So let's just have a look at what's in that script file first. So here is the name of our function and the function is going to need the variables and the group variable. So I want to create the means and the standard deviation by group. So I have to tell it what group variable is and what variables I want to do that for. So here I have put in some comments throughout that you can have a look at showing what each line does. That may help you in other circumstances create your own function code. But I'm just going to skip over that and head back to plots and see how we then tell it to run that function. So we would give it the name of the function and the variables instead of creating a new object with the variables listed I'm just going to tell it to draw those variables from the MF data frame. So from MF the variables I want to run this function on are variables 4 to 11, columns 4 to 11 and from MF as well the grouping variable is in column 2. So remember to run a function first I have to click back to the function and select everything in that function and run that first because now it knows to expect something, a code of text using this function providing the variables and the group variables. So now I can go back to my code and run this line here and I can have a look at my output now. So the means are given first so here are my groups and for each of my variables I have been I've got the mean for each of those by group and then I've got the up to variable 9 and then I've got the standard deviations for up to variable 9 and then it also spits out the sample sizes in each of those groups as well by variable. That can be really helpful because it can tell you if in some variables I'm missing a lot of data for some groups for example. So that's great I've got that but I actually want to be able to plot it so how can I manipulate this data? Remember at the start of the lecture I said don't just be constrained by how you get your data think about what you can do with it and that's what we're doing here. We've got a big data set but we were more interested in just the averages of our groups and their variation within so the standard deviation. We're more interested in plotting that so I've got that now in this output but it's not really in a big usable form just yet so I need to manipulate it a little bit. So what I did was I copied the means of the data so I copied this information here the means into a text file and I created mfmeans.txt and now I'm just going to read that into R and call it mfmeans.and that's imported correctly. I might just quickly have a look at that data just to show you that it's actually imported. Okay, so I've just got exactly what I had before but now it's in a data frame within R. It's not just as the output from some other function. I can actually now use this. So now I'm going to use a package called reshape2. So you'll need to install that reshape2 package and I'm just going to call that. This reshape package has heaps of really helpful little functions in it. So if you Google reshape2 for R you'll find the PDF that goes through all the things that it can do. But what we're going to do is we're going to create a new output file called mfmeans melt. So basically within reshape2 there's this function called melt and we're going to apply it to our mfmeans data frame that we just created. And it needs an ID variable and that's going to be our group. Now group comes from the mfmeans data frame. There's the variable there called group. So we're going to draw it from there. Now you'll see I've put brackets right around this data. Remember that what that does is it will print out the results straight to the console without me having to then select the name of mfmeans melt. So if you recall just here to show in the console window the mfmeans I had to run just the name. If I had brackets around that whole row it would have automatically printed it to the console window. So I'm just going to run this now and you'll see I get my output. So what it's done is it has taken this data and rearranged it into one column. So basically it's group 1 and the value for x2. So it's got this data here as the first five rows. So that's the same. Then it's repeated. It's taken this x3 and put it under there and repeated the labelling. So I've just created one long column. Now this is in the form that I can actually use for plotting. So what I want to do now is attach that mfmeans melt. I want this to be the data that I use in my plot. So this is called mfmeans melt and so I'm going to attach that. And you'll see that in mf I had a variable called group. Now because I've attached a new data frame it's masking group from mf and using the group variable from mfmeans melt. So this is again the importance to remember when you're using attach. It masks variable names that are the same from previous data frames and is using the current one only. And that's OK in this case because that's what I want it to do. So now I want to plot profiles for the groups. So the original one we did this profile plot over on the right here. That was by individuals. What I want to do is do a profile plot by the group. So to do that I'm going to need ggplot2. So you'll need to install the package ggplot2 and then I'm going to just call that. Now in ggplot2 I'm going to use my mfmeans melt data set and I'm going to use the variable and the value. So I'm just going to scroll up in the console window again. This is called variable and value so that's there what I'm going to use in my plotting and my group I'm going to colour it by my group variable. The geom point size will manipulate the size of the points in the graph and we can have lines as well. So I'm just going to run that and we can see what it looks like. It's often easier to run the code, see what it looks like and then work back through the code and you can see what each bit does. So I'm just going to zoom that so we can see it a little bit better. So basically the geom point size was the size of the little dots and then the line code joined things up with the line. And here are my actual variables now across the x-axis and not the individuals. Now this is similar to the profile plot 3.6 in Manly which was a bar chart. In that one they ranked them from smallest to largest. These aren't ranked, these are just in order here. And also he used the smaller mandible data set. So he only had I think six variables and we've got eight I think. So it's not exactly the same but it's the same intent in that we're plotting the means of the variables and then looking how they change over the groups and not the individuals. Again this plot would be much better if I had in my the actual species names here rather than just the numbers and the variable names across here. Sometimes it is better to use coding on your x-axis if your variable names are very large and it just makes it impossible to read. You can have a key for these variables somewhere else in your document if that makes it easier. But this legend here would be much better if I had the species name written here so I could see what for a start which is blue, what species is that that's acting weird, or much different to the others anyway on variables seven and eight. So that seemed a little bit convoluted but I really encourage you to work through that step by step and make sure you understand what I did at each point. Basically I had a really big data set. I didn't want to plot individuals. I wanted to plot the means so I had to figure out how to rearrange that data set. I used this existing function to do that. That gave me the data in a particular form. It was the correct values but it wasn't in the form that I needed it. So then I found another function that let me rearrange it and reorganise it. Now I could have taken that original data, put it into Excel, calculated the means, rearranged it the way I wanted and created a text file and brought that into R. That's not reproducible research. You can do that but then if you came back to it with another data set, you'd have to go figure those steps out again and go through them again. This way I can apply this process now to any data set. So it's much better to go to the effort at this point, write yourself some good notes so you remember what each step does and then it's completely reproducible. If I do this on a data set, you can take this code and apply it to the same data set and get exactly the same results. Or you can apply it to another data set and make the whole process much easier. So keep as much in code as you can. Don't mix code and point and clicking or taking it to Excel and manipulating that way. Try and do as much in code as possible. Also when you've got really big data sets, taking that into Excel is not an option. Excel is limited in size. So if you can get a handle on this coding in R and how to manipulate, I mean you may have come up with a better way to do it than I've done it here. There's always different ways to do things. So if you have used R a bit or you stumble across a process that would have been much cleaner than what I've done here, absolutely feel free to share that on the forum. I'm pretty sure there would have been a way for me to take that original output from the function to create the means and extract that output rather than me putting that into a text file and then importing it. So there's probably a step there that I could have done in code as well. So if you come across that, if you know how to do that, please share that. That would be really helpful. Here I've just done structure of that MF means melt. I probably should have shown you that a little bit earlier. That was just showing you that we just had group variable and value in there and that there's 40 observations and three variables. Okay, so I'm just going to detach now the MF and probably I should detach here MF melt as well. Okay, so I'm going to switch to a new data file now. Now this isn't one that's included in Manly, but Manly showed a churn off phases plot in figure 3.4. I'm just going to show you something similar but a bit, you know, sort of an alternative to that because that's difficult to do in R. And I'm going to use this twdecade.dat, which is available on the study desk. I'm just going to have a quick look at the head of that. So basically we have the decade, we have the rainfall, maximum temperature, minimum temperature, radiation, pan and VPD. So basically just some atmospheric variables by decade. It's a pretty small data set. So basically I'm going to create a stars plot, which is similar to the churn off plot in figure 3.4 of Manly. So I'm going to use columns two to four. So rain, max T and minty. So basically just some weather variables I want to use. And I want to draw segments in my stars plot. Yes, I do. And for the labels, I want to use column one. So that's going to be decades. So in figure 3.4, Manly used the canine data set. So he was using the labels or the grouping was based on the species. I'm going to use decade here from the data set. And we can put a main title on our plot and the key location. I'll show you what that means once we print out the plot. So I'll just run this data first and zoom this in so I can see it a little bit better. Oops, here we go. Sorry. OK, so the key is down the bottom here. We have rain, minty and max T. So we've got rain as black, minimum temperature as green, a maximum temperature as red. And you can see that we've got by our decade. So we've got a plot for each decade. Now, the size of the different segments of the circles, they are relative to each other. So they're not large here. A large black segment here means we had high rain in this decade relative to the other decades. OK, so it's not some objective standard of high rain. It's just within the context of this data set. So rainfall in 1950 was much higher than 1900 or 1910. Now, I'm just going to show you the data. This is the original world data. And we can see that minimum temperature here, the lowest minimum temperature was in 1960. So sometimes it's helpful to go back to the world data, make sure you're interpreting correctly. So we should have the smallest piece of the circle for minimum temperature in 1960. So if we just click back to the plot now, in 1960, green minimum temperature doesn't show up at all. So that means it was the minimum temperature was lowest here and green here. The minimum temperature. This is a higher value for minimum temperature. So this was 10 degrees and this was 11 degrees, something like that. For maximum temperature, it works the same way. So the highest maximum temperatures should have been around 1990 and the lowest maximum temperatures should have been around 1960. So if we look here, maximum temperatures 1990 had the highest maximum temperatures and 1960 was around, yes, sort of one of the lowest maximum temperatures there. So this is an alternative to figure 3.4 in Manley, those churn off faces. Again, you need a categorical variable here to make this work. And if you had too many slices of the pie here, it would be really difficult to interpret. Again, make sure you only interpret these slices of pie relative to each other, not some absolute standard. So I'm just going to close that now and we'll close this data set. OK, so that's it for plotting. So I'm just going to go back to the PDF file now and see where we got up to. So we worked all through these examples here. Here's where our 3D movable plots. This was our MF row, our multiple figure by row. And this was our function and our different profile plots. This is that profile plot that I showed you without the lines on it. So that can also be a way to approach it. And this is it with the lines on it. And this was our stars plot as an alternative to the churn off and a bit of an interpretation, a trend of increasing rainfall black from the 1900s to the 1950s. So black sort of increasing from 1900 all the way up to 1950s and it drops down again. And then a big jump in the 60s and a big jump in the 70s. The 90s were relatively dry. The 90s were also a relatively warm red decade and the 1960s a relatively cold green decade. You need to refer back to the database to get a good idea of the magnitude changes. So we looked at our slices of pie, but those actual values didn't change much. The from 10 degrees to 11 degrees isn't a very big change. Just another note on plotting that the reference card, which is in the R companion folder on week one on the study desk. Remember on that reference card, there's heaps of cheats for, well not cheats, just shortcuts and reminders for doing different plotting things. So different symbols, what code you can use, etc. When you're doing plotting, PCH is the type of symbol for points. LTY is the type of line. LAS is the orientation of the X of the, sorry, the axes labels. And CX is the size of the text and symbols. So make sure you have a bit of a play around with that. OK, so once you have tried these examples on your own and you've run through all the code, give the tutorial a go. There's also in the tutorial solutions I've provided code as well. And remember, you can copy and paste code from those PDF files straight into a new syntax file or code file in R. And then I really suggest that you do some Googling and have a look at different ways ggplot, latticeplot and baseplot can be used. Play around as much as you can with that because skills in plotting data are a great advantage and you get a much better idea of your data if you can plot it well.